# AUTOGENERATED! DO NOT EDIT! File to edit: ../surgtoolloc2/09_inference.ipynb.

# %% auto 0
__all__ = ['execute_in_docker', 'VideoLoader', 'UniqueVideoValidator', 'Surgtoolloc_det']

# %% ../surgtoolloc2/09_inference.ipynb 3
from fastai.vision.all import *
from ml_utils import *
from skimage.measure import label,regionprops,find_contours
from evalutils import DetectionAlgorithm
from evalutils.validators import UniquePathIndicesValidator,DataFrameValidator
from evalutils.exceptions import ValidationError
import json, random, SimpleITK, gc, cv2
from typing import Tuple, Dict
from pandas import DataFrame
import os

# %% ../surgtoolloc2/09_inference.ipynb 5
execute_in_docker = True

# %% ../surgtoolloc2/09_inference.ipynb 7
class VideoLoader():
    def load(self, *, fname):
        print('INSIDE Video Loader LOAD function.')
        path = Path(fname)
        print(path)
        if not path.is_file():
            raise IOError(
                f"Could not load {fname} using {self.__class__.__qualname__}."
            )
            #cap = cv2.VideoCapture(str(fname))
        #return [{"video": cap, "path": fname}]
        return [{"path": fname}]

# only path valid
    def hash_video(self, input_video):
        pass


class UniqueVideoValidator(DataFrameValidator):
    """
    Validates that each video in the set is unique
    """

    def validate(self, *, df: DataFrame):
        try:
            hashes = df["video"]
        except KeyError:
            raise ValidationError("Column `video` not found in DataFrame.")

        if len(set(hashes)) != len(hashes):
            raise ValidationError(
                "The videos are not unique, please submit a unique video for "
                "each case."
            )

# %% ../surgtoolloc2/09_inference.ipynb 9
class Surgtoolloc_det(DetectionAlgorithm):
    def __init__(self):
        
        print(' ')
        print('TeamZERO prediction engine has started!.')

        super().__init__(
            index_key='input_video',
            file_loaders={'input_video': VideoLoader()},
            input_path=Path("/input/") if execute_in_docker else Path("./test/input/"),
            output_file=Path("/output/surgical-tool-presence.json") if execute_in_docker else Path(
                "./test/output/surgical-tool-presence.json"),
            validators=dict(input_video=(UniquePathIndicesValidator(),)),
        )
        # loading ensemble learner
        print('-Loading key artefacts...')

        ensem_path=Path('/opt/algorithm/models') if execute_in_docker else Path("test/models")

        self.ensem_learner=[load_learner(m, cpu=True) for m in ensem_path.ls() if m.suffix=='.pkl']
        print(f'-{len(self.ensem_learner)} mutli-class classification models have been detected & loaded.')

        self.tool_list = ["needle_driver",
                          "monopolar_curved_scissor",
                          "force_bipolar",
                          "clip_applier",
                          "tip_up_fenestrated_grasper",
                          "cadiere_forceps",
                          "bipolar_forceps",
                          "vessel_sealer",
                          "suction_irrigator",
                          "bipolar_dissector",
                          "prograsp_forceps",
                          "stapler",
                          "permanent_cautery_hook_spatula",
                          "grasping_retractor"]
        print('-Tools dictionary loaded!.')
        print(' ')
        
    def extract_images(self, video_file):     
        
        print('-Image extraction started..')
        # start the loop
        count = 0
        src=Path('/images') if execute_in_docker else Path("./test/images/")
        for i in get_image_files(src): os.remove(i) 
        
        # read the video file  
        print(f'{str(self._input_path/Path(video_file).name)} READY FOR EXTRACTION')
        cap = cv2.VideoCapture(str(self._input_path/Path(video_file).name))
        
        while True:
            is_read, f = cap.read()
            if not is_read:
                # break out of the loop if there are no frames to read
                break
            name = str(src/f'im_{count}.jpg')
            cv2.imwrite(name,f)
            count+=1
        cap.release()
        print(f'--{len(get_image_files(src))} images from {video_file} are extracted in {src} folder. Extraction done!.')
        
    def tool_detect_json_sample(self):
        # single output dict
        slice_dict = {"slice_nr": 1}
        tool_boolean_dict = {i: False for i in self.tool_list}
        single_output_dict = {**slice_dict, **tool_boolean_dict}
        return single_output_dict
    
    
    def process_case(self, *, idx, case):
        print('Inside process_case()...')
        # Input video would return the collection of all frames (cap object)
        print(case)
        input_video_file_path = case #VideoLoader.load(case)
        # Detect and score candidates
        scored_candidates = self.predict(case.path) #video file > load evalutils.py

        # return
        # Write resulting candidates to result.json for this case
        return scored_candidates

    def save(self):
        with open(str(self._output_file), "w") as f:
            json.dump(self._case_results[0], f)


    def predict(self, fname) -> Dict:
        """
        Inputs:
        fname -> video file path
        
        Output:
        tools -> list of prediction dictionaries (per frame) in the correct format as described in documentation 
        """
        
        print(f'Processing the video file: {str(fname)} through TeamZERO prediction engine')
        print(f' ')
        self.extract_images(fname)
        print(' ')

        images_dir = Path('/images') if execute_in_docker else Path("./test/images/")
        fs=get_image_files(images_dir)
        
        num_frames = len(fs)
        
        print(' ')
        print(f'-Tools presence detection task started.')

        # generate output json
        all_frames_predicted_outputs = []
        all_undefined_tools=[]
        
        tta_res=[]
        prs_items=[]
        for learn in self.ensem_learner:
            learn.dls.bs=16
            learn.dls.n_workers=2
            tta_res.append(learn.tta(dl=learn.dls.test_dl(fs)))
            if len(prs_items)<1:
                prs_items=learn.dl.items

        print(f'--Predictions from all models in the ensemble learner are obtained!.')
        tta_prs=first(zip(*tta_res))
        tta_prs+=tta_prs[:1]
        tta_prs=torch.stack(tta_prs)

        lbls=[]
        for i in range(len(c)):
            arm_preds = tta_prs[:,:,cfg(i):cfg(i+1)].mean(0);
            arm_idxs = arm_preds.argmax(dim=1)
            arm_vocab = np.array(vocab[i])
            lbls.append(arm_vocab[arm_idxs])

        for usm1,usm2,usm3,usm4,f in zip(lbls[0],lbls[1],lbls[2],lbls[3],prs_items):
            frame_dict=self.tool_detect_json_sample()
            frame_dict['slice_nr']=int(f.stem.replace("im_",""))
            frame_dict[usm1]=True if usm1 in frame_dict.keys() else all_undefined_tools.append(usm1)
            frame_dict[usm2]=True if usm2 in frame_dict.keys() else all_undefined_tools.append(usm2)
            frame_dict[usm3]=True if usm3 in frame_dict.keys() else all_undefined_tools.append(usm3)
            frame_dict[usm4]=True if usm4 in frame_dict.keys() else all_undefined_tools.append(usm4)
            frame_dict.pop("nan", None)
            frame_dict.pop("blank", None)
            frame_dict.pop("out_of_view", None)
            all_frames_predicted_outputs.append(frame_dict) 
        
        print(f'--Translation of class probabilities to tool labels is done!.')
        
        print(f'--Following tools remained unaccounted for: {set(all_undefined_tools)}. Please ensure if it is OK to skip these tools from the output.')
        tools=sorted(all_frames_predicted_outputs, key=lambda d: d['slice_nr']) 

        print(f'--Output JSON file generated & returned!.')
        
        print(' ')
        
        print(f'{fname} has been successfully processed!.')
        
        print(' ')
        return tools

# %% ../surgtoolloc2/09_inference.ipynb 11
if __name__ == "__main__":
    Surgtoolloc_det().process()
